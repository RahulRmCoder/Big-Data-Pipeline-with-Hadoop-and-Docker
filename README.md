# Big-Data-Pipeline-with-Hadoop-and-Docker
This project implements a complete data processing pipeline using Hadoop and Docker. It collects and processes both structured and unstructured data from multiple synthetic sources, stores it in HDFS, processes it using Python, and creates visualizations.
